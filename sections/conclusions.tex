\section{Conclusions}

\begin{outline}
This work demonstrates that a greedy, neural network-based planner can generate robust, acyclic gaits for quadruped robots. By filtering actions through a learned evaluation network and selecting them via RL, the system bridges the gap between structured control and learning. Crucially, we find that while learned perception aids candidate generation, removing heuristic costs during policy training leads to superior, self-discovered locomotion strategies.
\end{outline}